{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Master_Harmony_GraphQL_to_GeoTiff.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "lMKrWDfmqkfo",
        "V-7B3Pmt4ErF",
        "WS_3ajYJj_wp",
        "LXMUsiaZdJ97"
      ],
      "authorship_tag": "ABX9TyMMxIStK8iB6XH/VeSZRRTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sea-surface-teleconnections/sea-surface-teleconnections/blob/main/Master_Harmony_GraphQL_to_GeoTiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✨ ⭐ Master Notebook ⭐ 🌈\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Datasets ⚡\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Ocean: \n",
        " - 🌊\n",
        "[GHRSST Level 4 AVHRR_OI Global Blended Sea Surface Temperature Analysis (GDS version 2) from NCEI](https://podaac.jpl.nasa.gov/dataset/AVHRR_OI-NCEI-L4-GLOB-v2.0?ids=Processing%20Levels:Keywords&values=4%20-%20Gridded%20Model%20Output::Oceans:Ocean%20Temperature&provider=PODAAC) \n",
        "\n",
        "Land/Atmosphere:\n",
        "\n",
        "- [GOES](https://www.ospo.noaa.gov/Products/imagery/archive.html)\n",
        "-[MODIS- Cloud/Vegitation](https://search.earthdata.nasa.gov/search?fi=MODIS) \n",
        "\n",
        "\n",
        "- [MERRA-2](https://disc.gsfc.nasa.gov/datasets?project=MERRA-2)\n",
        "\n",
        "- SMOS/SMAP Soil Moisture\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1hV52V0hTNy-pOkXZOpi0J2uuLqZag3QO?usp=sharing)\n",
        "\n",
        "> [Zarr Cloud native Resources](https://github.com/zarr-developers/tutorials/blob/main/zarr_cloud_native_geospatial_2022.ipynbtps://)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> [Zarr Resources](\n",
        "https://github.com/podaac/tutorials/blob/master/notebooks/SWOT-EA-2021/Estuary_explore_inCloud_zarr.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ">[Zarr Dataset Sample Examples](https://notebooks.githubusercontent.com/view/ipynb?color_mode=auto&commit=c7ee47ad1bc9f925d276c310223c631547284368&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f676973742f727369676e656c6c2d757367732f64353335313238393263366339666262623232613761653866376437386465652f7261772f633765653437616431626339663932356432373663333130323233633633313534373238343336382f74687265655f7a6172722e6970796e62&logged_in=false&nwo=rsignell-usgs%2Fd53512892c6c9fbbb22a7ae8f7d78dee&path=three_zarr.ipynb&repository_id=111446341&repository_type=Gist)\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "Zarr is about 10x faster than NetCDF in Cloud Object Storage\n",
        "Using 40 cores (20 dask workers), we were able to pull netCDF data from Google Cloud Storage at a rate of about 500 MB/s. Using the Zarr format, we could get to 5000 MB/s (5 GB/s) for the same number of dask workers.\n"
      ],
      "metadata": {
        "id": "MtmSSpwGVr-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Modules\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "DIRECT ACCESS\n",
        "PO.DAAC DRIVE\thttps://podaac-tools.jpl.nasa.gov/drive/files/allData/ghrsst/data/GDS2/L4/GLOB/NCEI/AVHRR_OI/v2\n",
        "PO.DAAC Drive\n",
        "OPENDAP DATA\thttps://podaac-opendap.jpl.nasa.gov/opendap/allData/ghrsst/data/GDS2/L4/GLOB/NCEI/AVHRR_OI/v2/\n",
        "The OPeNDAP base directory location for the collection.\n",
        "THREDDS\thttps://thredds.jpl.nasa.gov/thredds/catalog_ghrsst_gds2.html?dataset=AVHRR_OI-NCEI-L4-GLOB-v2.0\n",
        "THREDDS Data Server access for this dataset\n",
        "Web Service\thttps://podaac.jpl.nasa.gov/ws/search/granule/?datasetId=PODAAC-GHAAO-4BC02\n",
        "(Search Granule)\n",
        "Format\tNETCDF\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "umfUPi0fhG1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G4kqo-Xco4vv",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ef7a89-65f7-464c-9d09-0a6cac6a0a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: shapely>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.21.6)\n",
            "Collecting pyshp>=2\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: cartopy\n",
            "  Building wheel for cartopy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cartopy: filename=Cartopy-0.19.0.post1-cp37-cp37m-linux_x86_64.whl size=12516294 sha256=af943162651c601919141ad60f8e6e05ceb9e07c4f02a304923164ac797ffca4\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/01/f7/bd10aeb96fe4b518cde5f7c4f5e12c7202f85b7353a5017847\n",
            "Successfully built cartopy\n",
            "Installing collected packages: pyshp, cartopy\n",
            "Successfully installed cartopy-0.19.0.post1 pyshp-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting zarr\n",
            "  Downloading zarr-2.12.0-py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 14.5 MB/s \n",
            "\u001b[?25hCollecting asciitree\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from zarr) (1.21.6)\n",
            "Collecting numcodecs>=0.6.4\n",
            "  Downloading numcodecs-0.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.8 MB/s \n",
            "\u001b[?25hCollecting fasteners\n",
            "  Downloading fasteners-0.17.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from numcodecs>=0.6.4->zarr) (0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from numcodecs>=0.6.4->zarr) (4.1.1)\n",
            "Building wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5050 sha256=33b0449083c42bcc2a1eb76e4e7c0dc94d6862fe1de5943be77c4538950ec221\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/38/0def51e15add93bff3f4bf9c248b94db0839b980b8535e72a0\n",
            "Successfully built asciitree\n",
            "Installing collected packages: numcodecs, fasteners, asciitree, zarr\n",
            "Successfully installed asciitree-0.3.3 fasteners-0.17.3 numcodecs-0.10.2 zarr-2.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for json\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3!=1.25.0 in /usr/local/lib/python3.7/dist-packages (1.25.11)\n"
          ]
        }
      ],
      "source": [
        "#@title Module Install\n",
        "!pip install s3fs\n",
        "!pip install time\n",
        "!pip install requests\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install xarrray \n",
        "!pip install cartopy\n",
        "!pip install zarr\n",
        "!pip install json\n",
        "!pip install urllib3!=1.25.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aYu3FNV9o_WB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Module Install\n",
        "import s3fs\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy\n",
        "import zarr\n",
        "from IPython.display import HTML\n",
        "from json import dumps\n",
        "from json import loads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtkyKge7qWhw"
      },
      "source": [
        ">\n",
        ">\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnaOvGDfqWj8"
      },
      "source": [
        "# Setting Endpoints for Harmony API \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> Set a few endpoints for use during the remainder of the workflow:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> cmr = \"cmr.earthdata.nasa.gov\"\n",
        "urs = \"urs.earthdata.nasa.gov\"\n",
        "harmony = \"harmony.earthdata.nasa.gov\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IC6A-C-QChfF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sab5gSX3qUr3"
      },
      "outputs": [],
      "source": [
        "#@title End Point Links\n",
        "cmr = \"cmr.earthdata.nasa.gov\"\n",
        "urs = \"urs.earthdata.nasa.gov\"\n",
        "harmony = \"harmony.earthdata.nasa.gov\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UUIfpUF3Cilq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMKrWDfmqkfo"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "> https://podaac.jpl.nasa.gov/dataset/AVHRR_OI-NCEI-L4-GLOB-v2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Rq5rkc9_qjQM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f005d97b-20cc-48df-a966-a8ff385c70e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AVHRR_OI-NCEI-L4-GLOB-v2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#@title Short Name Query\n",
        "grace_ShortName = \"AVHRR_OI-NCEI-L4-GLOB-v2.0\"\n",
        "grace_ShortName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ieAWu4YerwxG",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "46cafc92-b89d-47bd-916b-7e3452e55fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting harmony\n",
            "  Downloading harmony-1.2.2402.tar.gz (165 kB)\n",
            "\u001b[K     |████████████████████████████████| 165 kB 14.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting antlr4-python3-runtime==4.9.3\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from harmony) (2.23.0)\n",
            "Collecting automata-lib\n",
            "  Downloading automata_lib-5.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting antlr-denter>=1.3.1\n",
            "  Downloading antlr_denter-1.3.1-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from harmony) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot->harmony) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->harmony) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->harmony) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->harmony) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->harmony) (1.25.11)\n",
            "Building wheels for collected packages: harmony, antlr4-python3-runtime\n",
            "  Building wheel for harmony (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for harmony: filename=harmony-1.2.2402-cp37-cp37m-linux_x86_64.whl size=365851 sha256=ff663139c1e21299fd99a104c31e182643aa614c964c6a415a9bf003395eb5e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/9f/fb/5dbeffbc4c8caeb4cf4347b52ac869bd627cd942c280db3b5a\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=6500dbd979de62cf8ffceebc6146b62f016ce1266ed19076b0ff88779eded577\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "Successfully built harmony antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, automata-lib, antlr-denter, harmony\n",
            "Successfully installed antlr-denter-1.3.1 antlr4-python3-runtime-4.9.3 automata-lib-5.0.0 harmony-1.2.2402\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting harmony-py\n",
            "  Downloading harmony_py-0.4.2-py3-none-any.whl (22 kB)\n",
            "Collecting curlify~=2.2\n",
            "  Downloading curlify-2.2.1.tar.gz (3.0 kB)\n",
            "Collecting sphinxcontrib-napoleon>=0.7\n",
            "  Downloading sphinxcontrib_napoleon-0.7-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests~=2.2 in /usr/local/lib/python3.7/dist-packages (from harmony-py) (2.23.0)\n",
            "Collecting python-dateutil~=2.7.5\n",
            "  Downloading python_dateutil-2.7.5-py2.py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 22.6 MB/s \n",
            "\u001b[?25hCollecting python-dotenv~=0.1\n",
            "  Downloading python_dotenv-0.20.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: progressbar2~=3.5 in /usr/local/lib/python3.7/dist-packages (from harmony-py) (3.38.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2~=3.5->harmony-py) (3.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2~=3.5->harmony-py) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.2->harmony-py) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.2->harmony-py) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.2->harmony-py) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.2->harmony-py) (2022.6.15)\n",
            "Collecting pockets>=0.3\n",
            "  Downloading pockets-0.9.1-py2.py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: curlify\n",
            "  Building wheel for curlify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for curlify: filename=curlify-2.2.1-py3-none-any.whl size=2672 sha256=5e233ef518dda2bfe6f31a70256970b66d6dceb8da83e918d3a72fea7491bb46\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/6f/f6/c8c15889b355eb3ef2df27118cccee350fa4f9c75bdd888e23\n",
            "Successfully built curlify\n",
            "Installing collected packages: pockets, sphinxcontrib-napoleon, python-dotenv, python-dateutil, curlify, harmony-py\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "prophet 1.1 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.5 which is incompatible.\u001b[0m\n",
            "Successfully installed curlify-2.2.1 harmony-py-0.4.2 pockets-0.9.1 python-dateutil-2.7.5 python-dotenv-0.20.0 sphinxcontrib-napoleon-0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (0.20.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from xarray) (4.1.1)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.7/dist-packages (from xarray) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from xarray) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1->xarray) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1->xarray) (2.7.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1->xarray) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray) (3.8.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datetime\n",
            "  Downloading DateTime-4.5-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 764 kB/s \n",
            "\u001b[?25hCollecting zope.interface\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 21.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from datetime) (2022.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface->datetime) (57.4.0)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-4.5 zope.interface-5.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pprint (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pprint\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: s3fs in /usr/local/lib/python3.7/dist-packages (2022.7.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from s3fs) (3.8.1)\n",
            "Requirement already satisfied: fsspec==2022.7.1 in /usr/local/lib/python3.7/dist-packages (from s3fs) (2022.7.1)\n",
            "Requirement already satisfied: aiobotocore~=2.3.4 in /usr/local/lib/python3.7/dist-packages (from s3fs) (2.3.4)\n",
            "Requirement already satisfied: botocore<1.24.22,>=1.24.21 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.3.4->s3fs) (1.24.21)\n",
            "Requirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.3.4->s3fs) (1.14.1)\n",
            "Requirement already satisfied: aioitertools>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.3.4->s3fs) (0.10.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (4.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (2.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->s3fs) (4.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.4->s3fs) (1.25.11)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.4->s3fs) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.4->s3fs) (2.7.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.4->s3fs) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->s3fs) (2.10)\n"
          ]
        }
      ],
      "source": [
        "#@title Module Harmony Client Install\n",
        "!pip install harmony\n",
        "!pip install requests\n",
        "!pip install -U harmony-py\n",
        "!pip install xarray\n",
        "!pip install datetime\n",
        "!pip install pprint\n",
        "!pip install s3fs\n",
        "\n",
        "from harmony import BBox\n",
        "from harmony import Client\n",
        "from harmony import Collection\n",
        "from harmony import Request \n",
        "from harmony import LinkType\n",
        "from harmony.config import Environment\n",
        "import requests\n",
        "from pprint import pprint\n",
        "import datetime as dt\n",
        "import s3fs\n",
        "import xarray as xr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Lets utilize the CMR API \n",
        "\n",
        "### 2. Inspect the access and service options that exist for collection\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fN1O468Kbz5R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oorbI_SgCmLw"
      },
      "outputs": [],
      "source": [
        "#@title CMR API\n",
        "# Lets utilize the CMR API skills we learned on Day 1 to inspect service metadata:\n",
        "url = 'https://cmr.earthdata.nasa.gov/search'\n",
        "# We want to search by collection to. inspect the access and service options that exist:\n",
        "collection_url = f'{url}/{\"collections\"}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBvireFBJ8S4"
      },
      "source": [
        "We are going to focus on GHRSST Level 4P Global Sea Surface Skin Temperature from the Moderate Resolution Imaging Spectroradiometer (MODIS) on the NASA Aqua satellite (GDS2).\n",
        "\n",
        " Let’s first save this as a variable that we can use later on once we request data from Harmony.\n",
        "\n",
        "\n",
        " ❓ double check this "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dONKIRLJuO5O"
      },
      "source": [
        "AVHRR_OI-NCEI-L4-GLOB-v2.1\tGHRSST Level 4 AVHRR_OI Global Blended Sea Surface Temperature Analysis (GDS2) from NCEI\tC2036881712-POCLOUD\t2016-01-01T00:00:00.000Z\t[NaT/Prese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JsVMo7-3Ctep"
      },
      "outputs": [],
      "source": [
        "short_name= 'AVHRR_OI-NCEI-L4-GLOB-v2.1'\n",
        "concept_id = 'C2036881712-POCLOUD'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "❌❌❌❌❌❌❌ Fix this before pushing ❌❌❌❌❌❌❌\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-2-0KwwmDpDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mLUvwJk7s1Zf"
      },
      "outputs": [],
      "source": [
        "harmony_client = Client(auth=('CHANGEME', 'CHANGEME'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jro8RvM7KA2Z"
      },
      "source": [
        "We will view the top-level metadata for this collection to see what additional service and variable metadata exist.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">"
      ],
      "metadata": {
        "id": "LdZJ5H1fD7LJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">"
      ],
      "metadata": {
        "id": "pH9AQEdpD4Bm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkeWb7WI3GCm"
      },
      "source": [
        "# Collection (dataset) using 'Request'\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Get the UMM Collection metadata using requests.get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dFg4bNaAtQP5"
      },
      "outputs": [],
      "source": [
        "response = requests.get(url=f\"https://{cmr}/search/collections.umm_json\", \n",
        "                        params={\n",
        "                            'concept_id': concept_id,\n",
        "                            },\n",
        "                        headers={\n",
        "                            'Accept': 'application/json'\n",
        "                            }\n",
        "                       )\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTn4iy4KqnsW",
        "outputId": "10c6183a-fa57-4b04-9228-cd8f6df16fda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "response['hits']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8iJcqS3LfO"
      },
      "source": [
        "There should be only one result. Select and print its CMR Search metadata:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-DXcsuivMQV",
        "outputId": "27b20b2e-3de5-45bf-b453-50d967ade0f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'associations': {'services': ['S2004184019-POCLOUD'],\n",
              "  'tools': ['TL2108419875-POCLOUD'],\n",
              "  'variables': ['V2146304112-POCLOUD',\n",
              "   'V2110155274-POCLOUD',\n",
              "   'V2112015409-POCLOUD',\n",
              "   'V2110155270-POCLOUD',\n",
              "   'V2112015413-POCLOUD',\n",
              "   'V2146304110-POCLOUD',\n",
              "   'V2110155268-POCLOUD',\n",
              "   'V2112015411-POCLOUD',\n",
              "   'V2110155272-POCLOUD']},\n",
              " 'concept-id': 'C2036881712-POCLOUD',\n",
              " 'concept-type': 'collection',\n",
              " 'deleted': False,\n",
              " 'format': 'application/vnd.nasa.cmr.umm+json',\n",
              " 'has-formats': True,\n",
              " 'has-spatial-subsetting': True,\n",
              " 'has-temporal-subsetting': True,\n",
              " 'has-transforms': False,\n",
              " 'has-variables': True,\n",
              " 'native-id': 'GHRSST+Level+4+AVHRR_OI+Global+Blended+Sea+Surface+Temperature+Analysis+(GDS2)+from+NCEI',\n",
              " 'provider-id': 'POCLOUD',\n",
              " 'revision-date': '2022-06-16T16:36:42.938Z',\n",
              " 'revision-id': 12,\n",
              " 's3-links': ['podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/',\n",
              "  'podaac-ops-cumulus-public/AVHRR_OI-NCEI-L4-GLOB-v2.1/'],\n",
              " 'user-id': 'wenhaoli'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "grace_coll_meta = response['items'][0]['meta']\n",
        "grace_coll_meta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdsZri1c3cNS"
      },
      "source": [
        ">\n",
        ">\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1xE0ynH3OLZ"
      },
      "source": [
        "Granule (file)\n",
        "Get the UMM Granule metadata using requests.get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "amqi6Ko03d6z"
      },
      "outputs": [],
      "source": [
        "response = requests.get(url=f\"https://{cmr}/search/granules.umm_json\", \n",
        "                        params={\n",
        "                            'concept_id': concept_id,\n",
        "                            },\n",
        "                        headers={\n",
        "                            'Accept': 'application/json'\n",
        "                            }\n",
        "                       )\n",
        "response_gran = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akmg_uRF3sHR",
        "outputId": "21eb17cc-d01a-4b05-aa28-d8bff9e7b8f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2409"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "grace_gran = response.json()\n",
        "grace_gran['hits']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gff3q9r53PHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af39ac5-1776-4e76-e745-c6c0718a9c29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'concept-id': 'G2049048962-POCLOUD',\n",
              " 'concept-type': 'granule',\n",
              " 'format': 'application/vnd.nasa.cmr.umm+json',\n",
              " 'native-id': '20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1',\n",
              " 'provider-id': 'POCLOUD',\n",
              " 'revision-date': '2021-11-15T17:38:42.624Z',\n",
              " 'revision-id': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "grace_gran['items'][0]['meta']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xzqQ7Kh3wxK"
      },
      "source": [
        "As you can see, one result was returned (one hit). Print the CMR Search metadata for the granule (meta):\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTn78HXV36wM"
      },
      "source": [
        "The other component in each result (from the list of items) is the UMM metadata, accessible from the umm key. Print the RelatedUrls metadata field for the granule:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "V0NUAQmd3ygR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from json import dumps\n",
        "\n",
        "# Serializing json \n",
        "json_object = json.dumps(grace_gran['items'][0]['umm']['RelatedUrls'], indent = 4)"
      ],
      "metadata": {
        "id": "1ljMhP_SeOoM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50393738-e661-4135-c7ae-af291e4ad942",
        "id": "srhokgPhgahQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"URL\": \"s3://podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\",\n",
            "        \"Type\": \"GET DATA VIA DIRECT ACCESS\",\n",
            "        \"Description\": \"This link provides direct download access via S3 to the granule.\"\n",
            "    },\n",
            "    {\n",
            "        \"URL\": \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/AVHRR_OI-NCEI-L4-GLOB-v2.1/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc.md5\",\n",
            "        \"Description\": \"Download 20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc.md5\",\n",
            "        \"Type\": \"EXTENDED METADATA\"\n",
            "    },\n",
            "    {\n",
            "        \"URL\": \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\",\n",
            "        \"Description\": \"Download 20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\",\n",
            "        \"Type\": \"GET DATA\"\n",
            "    },\n",
            "    {\n",
            "        \"URL\": \"https://archive.podaac.earthdata.nasa.gov/s3credentials\",\n",
            "        \"Description\": \"api endpoint to retrieve temporary credentials valid for same-region direct s3 access\",\n",
            "        \"Type\": \"VIEW RELATED INFORMATION\"\n",
            "    },\n",
            "    {\n",
            "        \"URL\": \"https://opendap.earthdata.nasa.gov/providers/POCLOUD/collections/GHRSST%20Level%204%20AVHRR_OI%20Global%20Blended%20Sea%20Surface%20Temperature%20Analysis%20(GDS2)%20from%20NCEI/granules/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1\",\n",
            "        \"Type\": \"USE SERVICE API\",\n",
            "        \"Subtype\": \"OPENDAP DATA\",\n",
            "        \"Description\": \"OPeNDAP request URL\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(json_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDGnzHMP39g8"
      },
      "source": [
        "We want the URL corresponding to 'Type': 'GET DATA'. Select the URL from appropriate item in the list, then print:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PZ1gWUJb3_1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "befd0b7f-4bd5-4cfd-d85d-3a150a0b7636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "grace_url = grace_gran['items'][0]['umm']['RelatedUrls'][2]['URL']\n",
        "grace_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-7B3Pmt4ErF"
      },
      "source": [
        "\n",
        ">\n",
        "\n",
        "# Downloading a regular netcdf file from cloud \n",
        "Then do a regular https download\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wpOyE3ZK4Eaa"
      },
      "outputs": [],
      "source": [
        "r = requests.get(grace_url)\n",
        "with open('GHRSST_Level4_AVHRR_OI_Global Blended_SST_Analysis.nc', 'wb') as f:\n",
        "    f.write(r.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Large Files \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Read Meta Data Information First\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRIUTEJgdI3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from netCDF4 import Dataset    \n"
      ],
      "metadata": {
        "id": "AvQJSPMFdI3F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset('/content/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1 (1).nc', 'r')\n",
        "# print some metadata\n",
        "print(data)\n",
        "data.close()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e9dd44-9867-483d-c87f-b2061e198d4d",
        "id": "5ig-ekgodI3F"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'netCDF4._netCDF4.Dataset'>\n",
            "root group (NETCDF4 data model, file format HDF5):\n",
            "    Conventions: CF-1.6, ACDD-1.3\n",
            "    title: NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2 - Final\n",
            "    id: NCEI-L4LRblend-GLOB-AVHRR_OI\n",
            "    references: Reynolds, et al.(2009) What is New in Version 2. Available at http://www.ncdc.noaa.gov/sites/default/files/attachments/Reynolds2009_oisst_daily_v02r00_version2-features.pdf;Daily 1/4 Degree Optimum Interpolation Sea Surface Temperature (OISST) - Climate Algorithm Theoretical Basis Document, NOAA Climate Data Record Program CDRP-ATBD-0303 Rev. 2 (2013). Available at http://www1.ncdc.noaa.gov/pub/data/sds/cdr/CDRs/Sea_Surface_Temperature_Optimum_Interpolation/AlgorithmDescription.pdf.\n",
            "    institution: NOAA/NESDIS/NCEI\n",
            "    creator_name: NCEI Products and Services\n",
            "    creator_email: ncei.orders@noaa.gov\n",
            "    creator_url: http://www.ncdc.noaa.gov/oisst\n",
            "    gds_version_id: v2.0r5\n",
            "    netcdf_version_id: 4.3.2\n",
            "    date_created: 20200116T000000Z\n",
            "    product_version: Version 2.0\n",
            "    history: 2015-10-28: Modified format and attributes with NCO to match the GDS 2.0 rev 5 specification.\n",
            "    spatial_resolution: 0.25 degree\n",
            "    start_time: 20160101T000000Z\n",
            "    stop_time: 20160102T000000Z\n",
            "    westernmost_longitude: -179.875\n",
            "    easternmost_longitude: 179.875\n",
            "    southernmost_latitude: -89.875\n",
            "    northernmost_latitude: 89.875\n",
            "    file_quality_level: 3\n",
            "    source: UNKNOWN,ICOADS SHIPS,ICOADS BUOYS,ICOADS argos,MMAB_50KM-NCEP-ICE\n",
            "    comment: The daily OISST version 2.0 data contained in this file are the same as those in the equivalent GDS 1.0 file.\n",
            "    summary: NOAAs 1/4-degree Daily Optimum Interpolation Sea Surface Temperature (OISST) (sometimes referred to as Reynolds SST, which however also refers to earlier products at different resolution), currently available as version 2, is created by interpolating and extrapolating SST observations from different sources, resulting in a smoothed complete field. The sources of data are satellite (AVHRR) and in situ platforms (i.e., ships and buoys), and the specific datasets employed may change over time. At the marginal ice zone, sea ice concentrations are used to generate proxy SSTs.  A preliminary version of this file is produced in near-real time (1-day latency), and then replaced with a final version after 2 weeks. Note that this is the AVHRR-ONLY DOISST, available from Oct 1981, but there is a companion DOISST product that includes microwave satellite data, available from June 2002.\n",
            "    acknowledgement: This project was supported in part by a grant from the NOAA Climate Data Record (CDR) Program. Cite this dataset when used as a source. The recommended citation and DOI depends on the data center from which the files were acquired. For data accessed from NOAA in near real-time or from the GHRSST LTSRF, cite as: Richard W. Reynolds, Viva F. Banzon, and NOAA CDR Program (2008): NOAA Optimum Interpolation 1/4 Degree Daily Sea Surface Temperature (OISST) Analysis, Version 2. [indicate subset used]. NOAA National Centers for Environmental Information. http://doi.org/doi:10.7289/V5SQ8XB5 [access date]. For data accessed from the NASA PO.DAAC, cite as: Richard W. Reynolds, Viva F. Banzon, and NOAA CDR Program (2008): NOAA Optimum Interpolation 1/4 Degree Daily Sea Surface Temperature (OISST) Analysis, Version 2. [indicate subset used]. PO.DAAC, CA, USA. http://doi.org/10.5067/GHAAO-4BC01 [access date].\n",
            "    license: No constraints on data access or use.\n",
            "    project: Group for High Resolution Sea Surface Temperature\n",
            "    publisher_name: NCEI Products and Services\n",
            "    publisher_email: ncei.orders@noaa.gov\n",
            "    publisher_url: http://www.ncdc.noaa.gov/oisst\n",
            "    naming_authority: org.ghrsst\n",
            "    time_coverage_start: 20160101T000000Z\n",
            "    time_coverage_end: 20160102T000000Z\n",
            "    platform: \n",
            "    sensor: \n",
            "    uuid: 7b6d2fda-475d-42cf-a228-2de550cc8188\n",
            "    geospatial_lat_units: degrees_north\n",
            "    geospatial_lat_resolution: 0.25\n",
            "    geospatial_lon_units: degrees_east\n",
            "    geospatial_lon_resolution: 0.25\n",
            "    Metadata_Conventions: ACDD-1.3\n",
            "    Metadata_Link.: http://doi.org/10.7289/V5SQ8XB5\n",
            "    keywords: Oceans>Ocean Temperature>Sea Surface Temperature\n",
            "    keywords_vocabulary: NASA Global Change Master Directory (GCMD) Science Keywords, Version 8.1\n",
            "    standard_name_vocabulary: CF Standard Name Table v29\n",
            "    processing_level: L4\n",
            "    cdm_data_type: Grid\n",
            "    dimensions(sizes): lat(720), lon(1440), nv(2), time(1)\n",
            "    variables(dimensions): float32 lat(lat), float32 lon(lon), int32 time(time), float32 lat_bnds(lat, nv), float32 lon_bnds(lon, nv), int16 analysed_sst(time, lat, lon), int16 analysis_error(time, lat, lon), int8 mask(time, lat, lon), int8 sea_ice_fraction(time, lat, lon)\n",
            "    groups: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1kUYI9nLVPp",
        "outputId": "e4e919db-707c-4b2d-f77f-a8b75420bb37"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">"
      ],
      "metadata": {
        "id": "VDn0t1_aoJzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">\n",
        ">\n",
        ">\n",
        ">\n"
      ],
      "metadata": {
        "id": "460LgipREIJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "McdUHGcWoPx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netCDF4\n",
        "!pip install nctoolkit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import datetime\n",
        "import numpy as np\n",
        "import netCDF4 as nc4\n",
        "import netCDF4\n",
        "from netCDF4 import num2date\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import nctoolkit as nc\n",
        "import datetime\n",
        "import os"
      ],
      "metadata": {
        "id": "6I2gtXgkMc9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22923a26-2afd-4cf3-9917-c84b3119b3ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nctoolkit\n",
            "  Downloading nctoolkit-0.5.3-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 15.1 MB/s \n",
            "\u001b[?25hCollecting ncplot>=0.0.5\n",
            "  Downloading ncplot-0.2.4-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (1.6.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (0.3.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (2.7.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (1.3.5)\n",
            "Collecting hvplot\n",
            "  Downloading hvplot-0.8.0-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (0.20.2)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (0.6.0)\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.7/dist-packages (from nctoolkit) (0.12.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from ncplot>=0.0.5->nctoolkit) (2.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ncplot>=0.0.5->nctoolkit) (1.21.6)\n",
            "Requirement already satisfied: jinja2<=3.0.3 in /usr/local/lib/python3.7/dist-packages (from ncplot>=0.0.5->nctoolkit) (2.11.3)\n",
            "Collecting datashader\n",
            "  Downloading datashader-0.14.1-py2.py3-none-any.whl (18.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.2 MB 827 kB/s \n",
            "\u001b[?25hRequirement already satisfied: holoviews in /usr/local/lib/python3.7/dist-packages (from ncplot>=0.0.5->nctoolkit) (1.14.9)\n",
            "Collecting metpy\n",
            "  Downloading MetPy-1.2.0-py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.3->ncplot>=0.0.5->nctoolkit) (2.0.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->ncplot>=0.0.5->nctoolkit) (21.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->ncplot>=0.0.5->nctoolkit) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->ncplot>=0.0.5->nctoolkit) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->ncplot>=0.0.5->nctoolkit) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->ncplot>=0.0.5->nctoolkit) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->ncplot>=0.0.5->nctoolkit) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->nctoolkit) (1.15.0)\n",
            "Requirement already satisfied: colorcet>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from datashader->ncplot>=0.0.5->nctoolkit) (3.0.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.7/dist-packages (from datashader->ncplot>=0.0.5->nctoolkit) (0.56.0)\n",
            "Collecting datashape>=0.5.1\n",
            "  Downloading datashape-0.5.2.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: param>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from datashader->ncplot>=0.0.5->nctoolkit) (1.12.2)\n",
            "Requirement already satisfied: dask[complete]>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from datashader->ncplot>=0.0.5->nctoolkit) (2.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from datashader->ncplot>=0.0.5->nctoolkit) (1.7.3)\n",
            "Requirement already satisfied: pyct>=0.4.5 in /usr/local/lib/python3.7/dist-packages (from datashader->ncplot>=0.0.5->nctoolkit) (0.4.8)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (1.3.0)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (2022.7.1)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (0.12.0)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting multipledispatch>=0.4.7\n",
            "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (1.0.4)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (5.4.8)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.1.1-py3-none-any.whl (830 kB)\n",
            "\u001b[K     |████████████████████████████████| 830 kB 57.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2022.1.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 69.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.12.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (2.2.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (7.1.2)\n",
            "Collecting cloudpickle>=0.2.1\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (57.4.0)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 55.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.1-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 69.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 71.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.10.0-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 70.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 73.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.0-py3-none-any.whl (779 kB)\n",
            "\u001b[K     |████████████████████████████████| 779 kB 71.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.1-py3-none-any.whl (778 kB)\n",
            "\u001b[K     |████████████████████████████████| 778 kB 72.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.0-py3-none-any.whl (776 kB)\n",
            "\u001b[K     |████████████████████████████████| 776 kB 73.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 71.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.1-py3-none-any.whl (766 kB)\n",
            "\u001b[K     |████████████████████████████████| 766 kB 60.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 48.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 27.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.1-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 66.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.0-py3-none-any.whl (715 kB)\n",
            "\u001b[K     |████████████████████████████████| 715 kB 57.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.1-py3-none-any.whl (705 kB)\n",
            "\u001b[K     |████████████████████████████████| 705 kB 69.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
            "\u001b[K     |████████████████████████████████| 699 kB 55.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.1-py3-none-any.whl (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 62.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.0-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 56.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.1-py3-none-any.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 56.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 67.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.2.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 66.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.1-py3-none-any.whl (672 kB)\n",
            "\u001b[K     |████████████████████████████████| 672 kB 45.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.0-py3-none-any.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 73.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2020.12.0-py3-none-any.whl (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
            "\u001b[K     |████████████████████████████████| 656 kB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->datashader->ncplot>=0.0.5->nctoolkit) (0.39.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->datashader->ncplot>=0.0.5->nctoolkit) (4.12.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nctoolkit) (2022.1)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0->dask[complete]>=0.18.0->datashader->ncplot>=0.0.5->nctoolkit) (1.0.1)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from holoviews->ncplot>=0.0.5->nctoolkit) (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.7/dist-packages (from panel->nctoolkit) (4.64.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from panel->nctoolkit) (5.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from panel->nctoolkit) (3.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from panel->nctoolkit) (2.23.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->panel->nctoolkit) (0.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->datashader->ncplot>=0.0.5->nctoolkit) (3.8.1)\n",
            "Requirement already satisfied: pooch>=0.1 in /usr/local/lib/python3.7/dist-packages (from metpy->ncplot>=0.0.5->nctoolkit) (1.6.0)\n",
            "Collecting matplotlib>=3.3.0\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 37.5 MB/s \n",
            "\u001b[?25hCollecting pint>=0.10.1\n",
            "  Downloading Pint-0.18-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from metpy->ncplot>=0.0.5->nctoolkit) (5.1.1)\n",
            "Collecting pyproj>=2.5.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from metpy->ncplot>=0.0.5->nctoolkit) (5.9.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->metpy->ncplot>=0.0.5->nctoolkit) (1.4.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
            "\u001b[K     |████████████████████████████████| 944 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.0->metpy->ncplot>=0.0.5->nctoolkit) (0.11.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=0.1->metpy->ncplot>=0.0.5->nctoolkit) (1.4.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.5.0->metpy->ncplot>=0.0.5->nctoolkit) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->panel->nctoolkit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->panel->nctoolkit) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->panel->nctoolkit) (1.25.11)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netCDF4->nctoolkit) (1.6.1)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->nctoolkit) (1.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->nctoolkit) (0.10.2)\n",
            "Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->nctoolkit) (0.6.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine->nctoolkit) (0.5.2)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine->nctoolkit) (3.3.0)\n",
            "Building wheels for collected packages: datashape\n",
            "  Building wheel for datashape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datashape: filename=datashape-0.5.2-py3-none-any.whl size=59438 sha256=1e4eef740266e9c18c2c8373b945724dda17487fe8a7d7a6562556952b4e48bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b7/80/333a5c3312ed4cd54f5d5b869868c14e0c6002cb5c7238b52d\n",
            "Successfully built datashape\n",
            "Installing collected packages: locket, cloudpickle, partd, multipledispatch, fonttools, distributed, pyproj, pint, matplotlib, datashape, metpy, hvplot, datashader, ncplot, nctoolkit\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "prophet 1.1 requires python-dateutil>=2.8.0, but you have python-dateutil 2.7.5 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-2.1.0 datashader-0.14.1 datashape-0.5.2 distributed-2.30.1 fonttools-4.34.4 hvplot-0.8.0 locket-1.0.0 matplotlib-3.5.2 metpy-1.2.0 multipledispatch-0.6.0 ncplot-0.2.4 nctoolkit-0.5.3 partd-1.2.0 pint-0.18 pyproj-3.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle",
                  "distributed",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please install CDO version 1.9.7 or above: https://code.mpimet.mpg.de/projects/cdo/ or https://anaconda.org/conda-forge/cdo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydap\n",
        "import pydap.client"
      ],
      "metadata": {
        "id": "KKXDUsB8xMqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943e8456-2b10-4901-d738-f15d198adcdb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydap\n",
            "  Downloading Pydap-3.2.2-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pydap) (1.21.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pydap) (4.6.3)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from pydap) (2.11.3)\n",
            "Collecting Webob\n",
            "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pydap) (1.15.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->pydap) (2.0.1)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=396c64ebcf30cd8395c9d25fb3712ac6f974be5a97f977574d35b819c03e94ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built docopt\n",
            "Installing collected packages: Webob, docopt, pydap\n",
            "Successfully installed Webob-1.8.7 docopt-0.6.2 pydap-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydap.client import open_url\n",
        "dataset = open_url('https://opendap.jpl.nasa.gov/opendap/hyrax/allData/ghrsst/data/GDS2/L2P/AMSRE/REMSS/v7/2002/152/20020601161248-REMSS-L2P_GHRSST-SSTsubskin-AMSRE-l2b_v07a_r00414.dat-v02.0-fv01.0.nc')\n",
        "# OPENDAP DATA\thttps://podaac-opendap.jpl.nasa.gov/opendap/allData/ghrsst/data/GDS2/L4/GLOB/NCEI/AVHRR_OI/v2/"
      ],
      "metadata": {
        "id": "SCsnyu7ouf7a"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://opendap.jpl.nasa.gov/opendap"
      ],
      "metadata": {
        "id": "da3v5ZJ5Ywex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRgepRhOxZmj",
        "outputId": "64817721-b7f2-4abf-cf87-b05c8f81bf7f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Mapping.keys of <DatasetType with children 'lat', 'lon', 'time', 'sea_surface_temperature', 'sst_dtime', 'dt_analysis', 'sses_bias', 'sses_standard_deviation', 'l2p_flags', 'quality_level', 'wind_speed', 'diurnal_amplitude', 'cool_skin', 'water_vapor', 'cloud_liquid_water', 'rain_rate'>>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Large Files \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Read Meta Data Information First\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "w0xs1NkpvKMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from netCDF4 import Dataset    \n"
      ],
      "metadata": {
        "id": "Gu-XZY1MvKMq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset('/content/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1 (1).nc', 'r')\n",
        "# print some metadata\n",
        "print(data)\n",
        "data.close()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vt-tQ8mWvKMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading MetaData from DataSet in 3 Lines\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "o8fTwzi_vKMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr"
      ],
      "metadata": {
        "id": "E_L0pOR0vKMq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hPJ_y3jF4xgl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = xr.open_dataset('/content/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1 (1).nc')\n",
        "data"
      ],
      "metadata": {
        "id": "pp38Lrl140Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install leafmap \n",
        "!pip install localtileserver"
      ],
      "metadata": {
        "id": "ZQgAeUk-cS73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import leafmap\n",
        "filename = '/content/20160101120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1 (1).nc'"
      ],
      "metadata": {
        "id": "PaF0j_kXjOer"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading directly with Leaflet\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WS_3ajYJj_wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_two = leafmap.read_netcdf(filename)"
      ],
      "metadata": {
        "id": "eHBCA_Ffj5ha"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_two)"
      ],
      "metadata": {
        "id": "lQyVK_NLkIG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the NetCDF\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   GeoTif\n",
        "*   GeoJson\n",
        "*   CSV\n",
        "\n"
      ],
      "metadata": {
        "id": "7iJ-BOb2kSRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading MetaData from DataSet in 3 Lines\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LXMUsiaZdJ97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "E31ja9yd4uHM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading to pandasdataframe\n",
        "\n",
        "ds1= xr.open_dataset(filename)"
      ],
      "metadata": {
        "id": "S-nTEADNDPbP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds2 = ds1.to_dataframe()"
      ],
      "metadata": {
        "id": "pg_whng3Dcmb"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "j0FjWDoqL2fA",
        "outputId": "3979c2f8-0f4e-4c49-a8a9-879a69b1ed95"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                lat_bnds  lon_bnds  analysed_sst  \\\n",
              "lat     lon      time       nv                                     \n",
              "-89.875 -179.875 2016-01-01 0     -90.00   -180.00           NaN   \n",
              "                            1     -89.75   -179.75           NaN   \n",
              "        -179.625 2016-01-01 0     -90.00   -179.75           NaN   \n",
              "                            1     -89.75   -179.50           NaN   \n",
              "        -179.375 2016-01-01 0     -90.00   -179.50           NaN   \n",
              "...                                  ...       ...           ...   \n",
              " 89.875  179.375 2016-01-01 1      90.00    179.50    271.410004   \n",
              "         179.625 2016-01-01 0      89.75    179.50    271.419983   \n",
              "                            1      90.00    179.75    271.419983   \n",
              "         179.875 2016-01-01 0      89.75    179.75    271.429993   \n",
              "                            1      90.00    180.00    271.429993   \n",
              "\n",
              "                                analysis_error  mask  sea_ice_fraction  \n",
              "lat     lon      time       nv                                          \n",
              "-89.875 -179.875 2016-01-01 0              NaN   2.0               NaN  \n",
              "                            1              NaN   2.0               NaN  \n",
              "        -179.625 2016-01-01 0              NaN   2.0               NaN  \n",
              "                            1              NaN   2.0               NaN  \n",
              "        -179.375 2016-01-01 0              NaN   2.0               NaN  \n",
              "...                                        ...   ...               ...  \n",
              " 89.875  179.375 2016-01-01 1              0.3   1.0               1.0  \n",
              "         179.625 2016-01-01 0              0.3   1.0               1.0  \n",
              "                            1              0.3   1.0               1.0  \n",
              "         179.875 2016-01-01 0              0.3   1.0               1.0  \n",
              "                            1              0.3   1.0               1.0  \n",
              "\n",
              "[2073600 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20428d08-56d8-4988-b727-f8ac853005eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>lat_bnds</th>\n",
              "      <th>lon_bnds</th>\n",
              "      <th>analysed_sst</th>\n",
              "      <th>analysis_error</th>\n",
              "      <th>mask</th>\n",
              "      <th>sea_ice_fraction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>time</th>\n",
              "      <th>nv</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">-89.875</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">-179.875</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2016-01-01</th>\n",
              "      <th>0</th>\n",
              "      <td>-90.00</td>\n",
              "      <td>-180.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-89.75</td>\n",
              "      <td>-179.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">-179.625</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2016-01-01</th>\n",
              "      <th>0</th>\n",
              "      <td>-90.00</td>\n",
              "      <td>-179.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-89.75</td>\n",
              "      <td>-179.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-179.375</th>\n",
              "      <th>2016-01-01</th>\n",
              "      <th>0</th>\n",
              "      <td>-90.00</td>\n",
              "      <td>-179.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">89.875</th>\n",
              "      <th>179.375</th>\n",
              "      <th>2016-01-01</th>\n",
              "      <th>1</th>\n",
              "      <td>90.00</td>\n",
              "      <td>179.50</td>\n",
              "      <td>271.410004</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">179.625</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2016-01-01</th>\n",
              "      <th>0</th>\n",
              "      <td>89.75</td>\n",
              "      <td>179.50</td>\n",
              "      <td>271.419983</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.00</td>\n",
              "      <td>179.75</td>\n",
              "      <td>271.419983</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">179.875</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2016-01-01</th>\n",
              "      <th>0</th>\n",
              "      <td>89.75</td>\n",
              "      <td>179.75</td>\n",
              "      <td>271.429993</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.00</td>\n",
              "      <td>180.00</td>\n",
              "      <td>271.429993</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2073600 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20428d08-56d8-4988-b727-f8ac853005eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20428d08-56d8-4988-b727-f8ac853005eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20428d08-56d8-4988-b727-f8ac853005eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We open the netcdf file (using open_dataset() method), convert it to a dataframe (to_dataframe() method) and write this object to a csv file (to_csv() method).\n",
        "\n",
        "\n",
        "ds2.to_csv('saved_frame_one.csv', index=False)\n",
        "\n",
        "#display(pd)\n"
      ],
      "metadata": {
        "id": "OL-ddsMXElee"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jrcfUBnpLyia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_3YTzDO0G_TU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}